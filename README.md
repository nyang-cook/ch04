# 음성-텍스트 및 텍스트-음성 변환 애플리케이션

## 프로젝트 설명
이 프로젝트는 **Whisper API**를 사용하여 사람의 음성을 텍스트로 변환하고, **OpenAI API**를 통해 응답을 생성한 후, **TTS (Text-to-Speech)** 기술을 사용해 다시 음성으로 변환하는 시스템입니다. 사용자는 음성으로 질문을 하고, 시스템은 텍스트를 처리하여 응답을 음성으로 다시 들려주는 상호작용을 제공합니다.

## 주요 기능

### 음성-텍스트 변환 (STT)
Whisper API를 이용하여 음성을 텍스트로 변환합니다.

### 텍스트 생성
OpenAI API를 사용하여 텍스트 기반으로 응답을 생성합니다.

### 텍스트-음성 변환 (TTS)
생성된 텍스트 응답을 음성으로 변환하여 사용자에게 전달합니다.

## 설치 방법

프로젝트를 실행하려면 필요한 종속성을 설치해야 합니다. 아래의 단계를 따라 환경을 설정하세요.

## 프로젝트 실행 방법

프로젝트를 실행하려면 필요한 종속성을 설치해야 합니다. 아래의 단계를 따라 환경을 설정하세요.

### 1. 가상 환경 설정

프로젝트 폴더에서 가상 환경을 생성합니다:

python -m venv venv

### 2. 가상 환경 활성화하기

- **Windows에서:**

.\venv\Scripts\activate

- **macOS/Linux에서:**

source venv/bin/activate

### 3. 필요한 패키지 설치하기

`pip`을 사용하여 필요한 라이브러리를 설치합니다:

pip install -r requirements.txt

`requirements.txt` 파일에는 다음이 포함되어야 합니다:

audiorecorder streamlit openai

## 사용 방법

종속성 설치가 완료되면 프로그램을 사용할 수 있습니다.

### 1. OpenAI API 키 설정하기

OpenAI API 키를 환경 변수에 설정하거나 코드 내에서 직접 설정합니다:

export OPENAI_API_KEY="your-api-key"

### 2. Streamlit 앱 실행하기

애플리케이션을 실행하려면 다음 명령어를 사용하세요:

streamlit run app.py

### 3. 애플리케이션과 상호작용하기

애플리케이션이 브라우저에서 열립니다. 사용자는 음성을 녹음하고, OpenAI의 응답을 받으며, 생성된 텍스트를 음성으로 변환해 들을 수 있습니다.

## 예시 흐름

1. **사용자가 음성을 입력**  
   시스템은 `audiorecorder` 패키지를 사용하여 음성을 캡처합니다.

2. **Whisper API**  
   캡처된 음성은 Whisper API에 전달되어 텍스트로 변환됩니다.

3. **OpenAI API**  
   변환된 텍스트는 OpenAI로 보내져 응답을 생성합니다.

4. **TTS (텍스트-음성 변환)**  
   생성된 텍스트 응답은 음성으로 변환되어 사용자에게 전달됩니다.
